{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\codej\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function For Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils Function\n",
    "\n",
    "def convert_to_number(series):\n",
    "    for i  in range(len(series)):\n",
    "        try:\n",
    "            series[i] = int(series[i])\n",
    "        except ValueError:\n",
    "            series[i] = None\n",
    "    return series\n",
    "\n",
    "\n",
    "def remove_html_tags_special_character(col: pd.Series) -> pd.Series:\n",
    "    tags_list = ['<p>' ,'</p>' , '<p*>',\n",
    "                 '<ul>','</ul>',\n",
    "                 '<li>','</li>',\n",
    "                 '<br>',\n",
    "                 '<strong>','</strong>',\n",
    "                 '<span*>','</span>',\n",
    "                 '<a href*>','</a>',\n",
    "                 '<em>','</em>','<br>','<br />','<div>','</div>','\\\\n','~']\n",
    "    for tag in tags_list:\n",
    "        col.replace(to_replace=tag,value='',regex=False,inplace=True)\n",
    "    return col\n",
    "\n",
    "punctuations_list = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "    temp = str.maketrans('', '', punctuations_list)\n",
    "    text = str(text)\n",
    "    return text.translate(temp)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    " \n",
    "    imp_words = []\n",
    " \n",
    "    # Storing the important words\n",
    "    for word in str(text).split():\n",
    "        word = word.lower()\n",
    " \n",
    "        if (word not in stop_words) and 'br' not in word:\n",
    "            imp_words.append(word)\n",
    " \n",
    "    output = \" \".join(imp_words)\n",
    " \n",
    "    return output\n",
    "\n",
    "def balance_data(df,y_column_name):\n",
    "    ham_msg = df[df[y_column_name] == 0]\n",
    "    spam_msg = df[df[y_column_name] == 1]\n",
    "    print(ham_msg.shape)\n",
    "    print(spam_msg.shape)\n",
    "\n",
    "    if len(ham_msg) >= len(spam_msg):\n",
    "        ham_msg.sample(n=len(spam_msg),random_state=42)\n",
    "    else:\n",
    "        spam_msg.sample(n=len(ham_msg),random_state=42)\n",
    "    return pd.concat([ham_msg, spam_msg],ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprcessor Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,X_column_name=\"C3\",y_column_name=\"C5\",split_ratio=[0.1,0.2]):\n",
    "    \"\"\"\n",
    "    Preprocess the data for model training\n",
    "    Arguments:\n",
    "    df: Dataframe of raw data\n",
    "    X_column_name: represent the input x column name in DataFrame\n",
    "    Y_Column_nameL represent the target y column name in DataFrame\n",
    "    split_ratio: use to define spliting ratio for training and testing data default is 0.2 (20% of data is use for testing and 80% for training)\n",
    "    \"\"\"\n",
    "    # Target value preprocessing\n",
    "    df = df[[X_column_name,y_column_name]] # C3 for input column ,C5 target column\n",
    "    df[y_column_name] = pd.Series(convert_to_number(df[y_column_name].to_list()),name=y_column_name)\n",
    "    df = df[ df[y_column_name] <= 1]\n",
    "\n",
    "    #input Value preprocessing\n",
    "    #Step 1 remove html Tags an extra special character\n",
    "    df[X_column_name] = remove_html_tags_special_character(df[X_column_name])\n",
    "    df[X_column_name].replace(to_replace='\\n',value='',inplace=True,regex=True)\n",
    "    df[X_column_name].replace(to_replace='\\\\?',value='',inplace=True,regex=True)\n",
    "    df[X_column_name].dropna(inplace=True)\n",
    "\n",
    "    # Balance Data\n",
    "    df = balance_data(df,y_column_name)\n",
    "    # Step 3 NLP Text Preprocessing\n",
    "    df[X_column_name] = df[X_column_name].apply(lambda x: remove_punctuations(x))\n",
    "    df[X_column_name] = df[X_column_name].apply(lambda text: remove_stopwords(text))\n",
    "    \n",
    "    if len(split_ratio) == 2:\n",
    "        train_x, test_x, train_y, test_y = train_test_split(df[X_column_name],df[y_column_name],test_size=split_ratio[1])\n",
    "        train_x, val_x, train_y, val_y = train_test_split(train_x,train_y,test_size=split_ratio[0])\n",
    "        return ((train_x,train_y), (val_x, val_y), (test_x, test_y))\n",
    "    else:\n",
    "        train_x, test_x, train_y, test_y = train_test_split(df[X_column_name],df[y_column_name],test_size=split_ratio[0])\n",
    "        return ((train_x, train_y), (test_x, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147509, 2)\n",
      "(36845, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Dataset/profane_clean_data.csv\",encoding=\"UTF-8\")\n",
    "train_set, val_set, test_set = preprocess(df,\"text\",\"is_offensive\",[0.1,0.2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Pre-build Bert Model Layer\n",
    "## Variants of bert (https://tfhub.dev/google/collections/bert/1)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "bert_preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model Wrapper ( input and output layer added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert model wth input and output layer wrapper\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'Inputs')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "embeed = bert_encoder(preprocessed_text)\n",
    "dropout = tf.keras.layers.Dropout(0.1, name = 'Dropout')(embeed['pooled_output'])\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'Dense')(dropout)\n",
    "# creating final model\n",
    "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU configuration for model training ( run only system have good GPU Card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Inputs (InputLayer)            [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_6 (KerasLayer)     {'input_type_ids':   0           ['Inputs[0][0]']                 \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_7 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_6[0][0]',          \n",
      "                                None, 768),                       'keras_layer_6[0][1]',          \n",
      "                                 'sequence_output':               'keras_layer_6[0][2]']          \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " Dropout (Dropout)              (None, 768)          0           ['keras_layer_7[0][13]']         \n",
      "                                                                                                  \n",
      " Dense (Dense)                  (None, 1)            769         ['Dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Model Summary to print\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model Compile with checkpoint callback and respective result metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model Compiling\n",
    "\n",
    "Metrics = [tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "           tf.keras.metrics.Precision(name = 'precision'),\n",
    "           tf.keras.metrics.Recall(name = 'recall')\n",
    "           ]\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"/profane_Model CheckPoints\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "# compiling our model\n",
    "model.compile(optimizer ='adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = Metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4148/4148 [==============================] - 2422s 584ms/step - loss: 0.2746 - accuracy: 0.8888 - precision: 0.8297 - recall: 0.5544 - val_loss: 0.2313 - val_accuracy: 0.9109 - val_precision: 0.8119 - val_recall: 0.7249\n",
      "Epoch 2/10\n",
      "4148/4148 [==============================] - 2418s 583ms/step - loss: 0.2385 - accuracy: 0.9054 - precision: 0.8197 - recall: 0.6714 - val_loss: 0.2291 - val_accuracy: 0.9078 - val_precision: 0.8906 - val_recall: 0.6173\n",
      "Epoch 3/10\n",
      "4148/4148 [==============================] - 2408s 581ms/step - loss: 0.2335 - accuracy: 0.9081 - precision: 0.8232 - recall: 0.6842 - val_loss: 0.2249 - val_accuracy: 0.9094 - val_precision: 0.8784 - val_recall: 0.6379\n",
      "Epoch 4/10\n",
      "4148/4148 [==============================] - 2406s 580ms/step - loss: 0.2331 - accuracy: 0.9079 - precision: 0.8197 - recall: 0.6876 - val_loss: 0.2163 - val_accuracy: 0.9138 - val_precision: 0.8702 - val_recall: 0.6713\n",
      "Epoch 5/10\n",
      "4148/4148 [==============================] - 2407s 580ms/step - loss: 0.2308 - accuracy: 0.9091 - precision: 0.8241 - recall: 0.6896 - val_loss: 0.2125 - val_accuracy: 0.9163 - val_precision: 0.8593 - val_recall: 0.6982\n",
      "Epoch 6/10\n",
      "4148/4148 [==============================] - 2406s 580ms/step - loss: 0.2313 - accuracy: 0.9094 - precision: 0.8230 - recall: 0.6928 - val_loss: 0.2131 - val_accuracy: 0.9175 - val_precision: 0.8296 - val_recall: 0.7421\n",
      "Epoch 7/10\n",
      "4148/4148 [==============================] - 2405s 580ms/step - loss: 0.2309 - accuracy: 0.9085 - precision: 0.8208 - recall: 0.6901 - val_loss: 0.2112 - val_accuracy: 0.9159 - val_precision: 0.8350 - val_recall: 0.7249\n",
      "Epoch 8/10\n",
      "4148/4148 [==============================] - 2412s 582ms/step - loss: 0.2287 - accuracy: 0.9098 - precision: 0.8240 - recall: 0.6947 - val_loss: 0.2102 - val_accuracy: 0.9162 - val_precision: 0.8519 - val_recall: 0.7060\n",
      "Epoch 9/10\n",
      "4148/4148 [==============================] - 2415s 582ms/step - loss: 0.2290 - accuracy: 0.9096 - precision: 0.8224 - recall: 0.6953 - val_loss: 0.2118 - val_accuracy: 0.9168 - val_precision: 0.8502 - val_recall: 0.7117\n",
      "Epoch 10/10\n",
      "4148/4148 [==============================] - 2418s 583ms/step - loss: 0.2291 - accuracy: 0.9097 - precision: 0.8223 - recall: 0.6958 - val_loss: 0.2178 - val_accuracy: 0.9127 - val_precision: 0.8958 - val_recall: 0.6403\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set[0], train_set[1],batch_size=32,validation_data=val_set,shuffle=True, epochs = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Inputs with unsupported characters which will be renamed to inputs in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 366). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/profane_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/profane_model\\assets\n"
     ]
    }
   ],
   "source": [
    "opt = tf.saved_model.SaveOptions(\n",
    "    namespace_whitelist=None,\n",
    "    save_debug_info=False,\n",
    "    function_aliases=None,\n",
    "    experimental_io_device=\"CPU:0\",\n",
    "    experimental_variable_policy=None,\n",
    "    experimental_custom_gradients=True\n",
    ")\n",
    "model.save(\"models/profane_model\",options=opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Save model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weight/profane_model_weight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 600s 521ms/step - loss: 0.2179 - accuracy: 0.9124 - precision: 0.9035 - recall: 0.6377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21792438626289368,\n",
       " 0.9124243855476379,\n",
       " 0.9035120606422424,\n",
       " 0.6377449035644531]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set[0],test_set[1],batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evalution  Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 314s 273ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pred = model.predict(test_set[0])\n",
    "pred_int = tf.cast(pred, tf.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codej\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.79650674, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([0.88672836, 0.        ]),\n",
       " array([29368,  7503], dtype=int64))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_set[1],pred_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
